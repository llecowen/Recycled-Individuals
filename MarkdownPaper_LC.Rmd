---
output: pdf_document
---
---
title: "The Effect of Recycled Individuals in the Jolly-Seber Model with Tag Loss"
author: 
output:
  pdf_document
--- 

```{r setwd, echo=FALSE}
#Set Working Directory to Laura & Emily's Joint Dropbox Folder
setwd("~/Documents/GitHub/Recycled-Individuals")
```


> \begin{center} {\large Emily Malcolm and Laura Cowen} \end{center}

> \textsc{Summary:} In mark-recapture studies, the Jolly-Seber model assumes that individuals never lose their tags. In practice however, we know that tag loss does occur. Cowen and Schwarz (2006) developed the Jolly-Seber model with tag loss that relaxes this assumption and allows for estimation of tag retention and abundance in double-tagging experiments. Recycled individuals occur when individuals lose all of their tags and are recaptured as "new" individuals. Typically, the effect of these recycled individuals is assumed negligible. With low tag-retention rates, high capture rates, and high survival rates, recycled individuals can produce overestimates of population size. These results are particularly noticeable in longer studies. Through a simulation-based study, we examine the effect of recycled individuals on parameter estimates. We determine under what conditions recycled individuals have the most impact and offer advice for study designs. 

> \begin{center} \textsc{Key words:} Mark-recapture; Jolly-Seber; Double-tagging; Tag loss; Complete tag loss; Recycling; Abundance. 
\end{center}

#Introduction
Mark-recapture studies utilize statistical techniques to estimate numerical characteristics about populations. Over $k$ sampling periods, individuals are captured, tagged, released and potentially recaptured at later sample times. The Jolly-Seber (JS) model (Jolly 1965, Seber 1965) is commonly used to model open populations since it can estimate parameters of interest such as population size and survival rates (Pollock et al, 1990). An important assumption of this model is individuals never lose their tags. However, when this assumption is violated, serious bias can occur in the parameter and variance estimates (Arnason and Mills, 1981). Double-tagging, the placement of two tags on an individual, can be used to estimate tag retention rates. Often a mixture of single- and double-tagged individuals is used for practical purposes. Cowen and Schwarz (2006) incorporated tag-loss by developing the Jolly-Seber tag-loss (JSTL) model for experiments where some fraction of individuals are double tagged. This model was further extended to account for heterogeneity in capture between groups (Xu et al, 2014). 

Occasionally in mark-recapture experiments, previously captured individuals lose all of their tags (complete tag loss). These individuals are either recognized upon recapture (for example, through scarring or fin clipping), and not re-tagged, or if unrecognized, these individuals would be tagged again and treated as "new" individuals. Individuals who lose both tags and are recaptured and re-tagged are known as recycled individuals.  For example, an individual with the following tag history over three sampling occasions {11 01 00} was double tagged at time 1, lost a tag between times 1 and 2, and may have lost it's last tag between sampling occasions 2 and 3.  Then it may have lost its last tag and if recapture at sampling occasion 3 it would result in a new individual with capture history {00 00 11}. If the rate of tag loss is small, bias in the population estimate will also be small for the Peterson estimators (Seber and Felton, 1981). Typically in the JS and JSTL models, the effect of recycled individuals is assumed to be negligible. However, in situations where tag retention is low and survival and recapture probabilities are high it is suspected that recycled individuals will bias population size estimates upwards. The purpose of this study was to investigate the effect of recycled individuals on parameter estimates in the JSTL model through simulation. 

#Methods

##The Jolly-Seber Model with Tag Loss (JSTL)
Many different models can be specified for the JSTL model where parameters are homogeneous or heterogeneous with respect to time or group (Cowen and Schwarz, 2006).  In the simplest form of the JSTL model, it is assumed that every individual present in the population at sampling occasion $k$ has capture probability, survival probability and tag retention probability that are homogeneous for all individuals in the population across all sampling occasions. For this study, we consider the homogeneous parameter form of the JSTL model with the exception that entry probabilities vary over time. 

###Assumptions
Assumptions of the JSTL model with constant survival, capture, and tag retention probabilities and time-varying entry probabilities are as follows:

- The effect of recycled individuals is negligible
- All individuals (marked and unmarked) are equally catchable, and that capture probabilities for all individuals are the same for all individuals at all sample time
- All individuals (marked and unmarked) have equal survival probabilities between all sample times
- All individuals have equal entry (birth or immigration) probabilities, but entry probabilities can vary between sample times
- All marked individuals have equal tag retention probabilities between all sample times
- For double-tagged individuals, tag loss is independent between tags 
- There is independence across all individuals
- The sampling period is relatively short compared to the interval between sampling times

###Notation
We use the following notation to describe the statistics or model parameters discussed in this study.

[//]: (*Statistics:*)
   
$$
  \begin{array}{ll}
      k= & \text{number of sample times} \\
      n_{\text{obs}}= & \text{the total number of individuals captured with no tags and treated as new individuals; when no}\\
      & \text{recycling is present, $n_\text{obs}$ is the number of unique individuals observed throughout the study}\\
  \end{array}
$$

[//]: (*Parameters:*)   
$$
  \begin{array}{ll}
      p= & \text{the probability that an individual is recaptured at a sample time given that the individual was alive}\\
      & \text{at the previous sample time} \\
      \phi=  & \text{the probability that an individual survives and remain in the population between a sample time}\\
      & \text{and the next sample time }\\
      b_j= & \text{the probability that an individual enters the system between sample times $j$ and $j+1$. $j=0,1,...,k-1$.}\\
       & \text{$b_0$ is the expected fraction of individuals alive just prior to the first sample time.}\\
      \upsilon= & \text{the probability that an individual captured will be lost on capture}\\
      T_d= & \text{the probability that an individual is marked with $d$ tags. Note that the probability of marking with a }\\
      & \text{single tag is one minus the probability of marking with a double tag: $T_1=1-T_2$}\\
      \lambda= & \text{the probability that an individual captured will  retain its tag between time periods given that}\\
      & \text{it remains alive}\\
      N= & \text{super-population size, the total number of individuals ever present in population and available for}\\
      & \text{capture during the study}\\
  \end{array}
$$


*Functions of Parameters:*   
$$
  \begin{array}{ll}
    b_j*= & \text{the expected fraction of the population remaining to enter the population that enters between}\\
    & \text{sample times $j$ and $j+1$, $j=0,1,...,k-1$.}\\
       & b_{j}* = \left\{\begin{array}{ll}
                          b_0 & \text{if $j=0$} \\
                          b_j / \sum_{u=j}^{k-1} b_u & \text{if $j=1,...,k-1$}\\
                          1 & \text{if $j=k-1$} \\
                      \end{array}\right. \\
    B_j= & \text{net births; the number of individuals who enter the population after sample time $j$ and survive}\\
    & \text{to sample time $j+1$; $j=0,1,...,k-1$. $B_0$ is the number of indiividuals alive just before the}\\
    & \text{first sample time. Note that $E(B_j|N)=Nb_j$. }\\
    \chi_{(f_i,l_i,nt)}= & \text{the probability that the individual with capture history $i$ is first seen at $f_i$ and not seen after}\\
    & \text{sample time $l_i$, with $nt$ tags. This is a recursive function of $\phi$, $p$, and $\lambda$. If $f_i=0$, this}\\
    & \text{indicates individuals not yet captured but alive at time $l_i$.}\\
    & \text{For individuals not yet captured:}\\
       & \chi_{(0,j,0)} = \left\{\begin{array}{ll}
                          1-\phi+\phi(1-p)\chi_{(0,j+1,0)} & \text{if $j<k$} \\
                          1 & \text{if $j=k$}\\
                      \end{array}\right. \\
    & \text{For single tagged individuals:}\\
       & \chi_{(f_i,j,1)} = \left\{\begin{array}{ll}
                          1-\phi+\phi(1-p)\lambda \chi_{(f_i,j+1,1)}+\phi(1-\lambda) & \text{if $j<k$} \\
                          1 & \text{if $j=k$}\\
                      \end{array}\right. \\
    & \text{For double tagged individuals:}\\
       & \chi_{(f_i,j,2)} = \left\{\begin{array}{ll}
                          1-\phi+\phi(1-p)\lambda^2 \chi_{(f_i,j+1,2)}+\phi(1-\lambda)^2+2\phi(1-p)\lambda(1-\lambda)\chi_{(f_i,j+1,1)} & \text{if $j<k$} \\
                          1 & \text{if $j=k$}\\
                      \end{array}\right. \\
    \psi_j= & \text{probability that an individual enters the population, is still alive and is not seen before time $j$; }\\
    &j=1,2,...,k\\ 
    N_j= & \text{population size at time $j$. E$(N_1|N)=B_0$, E$(N_{j+1}|N)=(N_j-N_j p \upsilon)\phi +B_j$, which is the }\\
    & \text{number of individuals that survive from time $j$ minus the number lost on capture plus the }\\
    & \text{number of births.}\\
  \end{array}
$$

<!--*Latent Variables:*
$$
%  \begin{array}{ll}
%  a_i= & \text{the alive status vector for individual $i$, $A_i={a_{i1},a_{i2},...,a_{ik}}$, $i=0,1,...,m$, indicating whether individual $i$}\\
%  & \text{is alive (1) or dead (0) at sample time $j$. } \\
%  g_i= & \text{the tag status vector for individual \textit{i}}
%  \end{array}
$$
-->

###Likelihood and Estimation
The likelihood of the JSTL model can be divided into three parts: the probability of observing $n_{\text{obs}}$, the number of tag histories, given the super-population size ($L_1^A$), the probability of observing recaptures given the number of tag histories ($L_1^B$), and the probability of observing the number of individuals lost on capture ($L_3$). 

The probability of observing $n_\text{obs}$ capture histories is given by a binomial distribution conditional on the super-population size. 
$$
L_1^A=[n_{\text{obs}}|N] \sim \text{Binomial} (N, 1-P_0) \text{, where}
$$ 
$$
P_0\text{ is the probability of never being seen, given by } P_0=\sum_{j=0}^{k-1} b_j (1-p) \chi_{(0,j+1,0)}. 
$$

The probability of observing each unique tag history $\omega_i$ is modeled by a multinomial conditional upon being observed at least once.
$$
L_1^B=[n_{\omega_i}|n_{obs}] \sim \text{Multinomial} (n_{obs}, \pi_{\omega_i}) \text{, where} 
$$
$$
\pi_{\omega_i}= P_{\omega_i}/(1-P_0) \text{ and}
$$
$$
P(\omega_i)=\psi_{f_i} T_d \left\{ \prod_{j=f_i}^{l_i} p^{w*_{ij}} (1-p)^{(1-w*_{ij})} \right\} \left\{ \phi^{l_i-1-f_i} \right\} \times \prod_{d=1}^{2} \left\{ \left( \lambda^{l_{id}-1-f_i} \right) \left(1- \lambda^{q_{id}-1-l_{id}} \right)^{I(l_{id} \neq l_i)} \right\} \times \chi_{f_i, l_i, nt_{l_i}}
$$

The third component $L_3$ models the number of losses on capture as a binomial. In this study we assume there is no possibility of loss on capture, this third component of the likelihood simplifies to 1. The full likelihood is given by the product of the components of the likelihood ($L=L_1^A \times L_1^B$) and can be found in the Appendix. Maximum Likelihood parameter estimates are found using Newton-Raphson method. Estimated standard errors are computed using the delta theorem. This technique estimates the variance in the function of the parameter of interest using a second order Taylor approximation. 

##Experimental Design
To study the effect of recycled individuals on parameter estimates of this model, we conducted a simulation study. Data were simulated and analyzed using R 3.1.1. Data sets varied both in super-population size, parameter values and percent double tagged. We generated data for the JSTL model with constant survival, capture, and tag retention probabilities for a double-tagging experiment. Super-population sizes of 1000 and 100000 were considered in order to determine the effect that population size may have on the results. For the super-population size of 100000, experiments with ten sampling occasions were considered. For the super-population size of 1000 we considered experiments with five, seven and ten sampling occasions in order to determine if the length of the study has any effect on the results. For each population size, we tested different proportions of double-tagged versus single-tagged individuals ($0.5$ and $1$). Survival, capture, and tag retention probability parameters were varied in a $3^3$ experimental design with low ($0.2$), medium ($0.5$) and high ($0.9$) values for each parameters. The entry rates were fixed to be 0.1 at each of the 10 sampling times. No individuals were lost on capture. 

###Simulation of Data 
For all of the parameter combinations of super-population size ($N=1 000, 100 000$), fraction double-tagged ($0.5, 1$), survival probability ($\phi=0.2,0.5,0.9$), capture probability ($p=0.2,0.5,0.9$) and tag retention probability ($\lambda=0.2,0.5,0.9$), we generated 100 data sets where the simulated data met all the assumptions of the model. 

For each individual, we simulate a capture history using the following algorithm:

  1.  Determine when the individual enters the population utilizing the entry probabilities.
  
  2.  For each time period after entry (until death or first capture) we determine if the individual survives to that time period (with probability $\phi$). If they are still alive, determine if they were first captured (with probability $p$). If they are captured, determine whether they are single or double-tagged. 
  
  3.  For each time period after first capture (until death, loss of all tags or the end of the study) determine if the individual survives to that time period (with probability $\phi$). Then if they are still alive, determine if they lose any of their tags (with probability $1-\lambda$). If they still have at least one of their tags, determine if they were recaptured (with probability $p$). If they have lost all of their tags, consider them as a new individual entering the population at this time period. 
  
By keeping track of all the recycled individuals, this algorithm can provide us with two data sets: one that includes the recycled individuals (assumes individuals, who have lost their tags, are tagged again upon recapture and treated as new individuals) and one that doesn't include the recycled individuals (assumes that individuals, who have lost their tags, can be recognized upon recapture and are not re-tagged). The JSTL model is fit to the 100 simulated data sets twice (once with and once without recycled individuals). We assume that any difference between the two analyses is due entirely to the recycled individuals. 

###Evaluation Criteria  
To evaluate the 100 resulting parameter estimates from each of the 100 simulations, we looked at several criteria including: average parameter estimate, relative bias of the estimates, the average standard error of the parameter estimates, the standard deviation of the parameter estimates, and root mean squared error (RMSE) of the parameter estimates. 

We calculated the mean parameter estimate as $\hat{p}= \frac{1}{100} \sum_{i=1}^{100} \hat{p_i}$, where the $\hat{p_i}$'s are the parameter estimates from each of the 100 simulations. We calculated average standard error of the parameter estimate as $\text{SE}(\hat{p})= \frac{1}{100} \sum_{i=1}^{100} \text{SE}(\hat{p_i})$. We calculated the standard deviation of the parameter estimates as $\text{SD}(\hat{p})= \sqrt{\frac{1}{99} \sum_{i=1}^{100} (\hat{p_i}-\hat{p})^2}$. We calculated the root mean square error of the parameter estimates as $\text{RMSE}= \sqrt{\frac{1}{100} \sum_{i=1}^{100} (\hat{p_i}-p)^2} \approx \sqrt{\hat{\text{SD}}^2+\hat{\text{Bias}}^2}$.

The average parameter estimates are compared to the true parameter values using relative bias. We calculated the relative bias of the estimators as $\left(\hat{p}\right) =(\hat{p} -p)/p$, where $\hat{p}$ is the average parameter estimate calculated from the 100 simulations and $p$ is the true value of the parameter. Often, we compared the relative bias from the analysis with the recycled individuals to the relative bias from the analysis without the recycled individuals. We calculated the difference in the two relative biases and consider this to be relative bias that was contributed entirely by the recycled individuals being tagged as "new" individuals.  

#Results 


```{r colors, echo=FALSE}
#colors for the paper
library(xtable)
library(RColorBrewer)
colors=c("#00246D","#2C7FB8","#7FCDBB","#EDF8B1","#F4FFF5")
```


```{r parameters, echo=FALSE}
#Define Parameters of 27 Models
globalPhi=c(rep(0.9,9),rep(0.5,9),rep(0.2,9))
globalP=c(rep(c(rep(0.9,3),rep(0.5,3), rep(0.2,3)),3))
globalLambda=c(rep(c(rep(0.9,1),rep(0.5,1), rep(0.2,1)),9))
library(graphics)
nsample=10
b=numeric(length=nsample) #probability of birth/immigration (sum to 1)
bstar=numeric(length=nsample) # expected fraction of population remaining entering the population
b[1:nsample]=1/nsample
bstar_to_b<-function(samp_time,std_bstar,nsample)
{ if(samp_time==1){b=std_bstar[samp_time]}
  else{ b=1;
        for(u in 1:(samp_time-1))
        { b=b*(1-std_bstar[u]);}
        b=b*std_bstar[samp_time];
  }
}
std_b=vector(length=nsample)

#Create matrix of true parameter values, 27 rows for each of the 27 different parameter combinations for N=100000
# Phi, P, Lambda, b1, b2, b3, b4, b5, b6, b7, b8, b9, b10, N1, N2, N3, N4, N5, N6, N7, N8, N9, N10, superN
parameters<-matrix(0,nrow=27,ncol=3+10+10+1)
parameters[,1]=globalPhi
parameters[,2]=globalP
parameters[,3]=globalLambda
for(i in 1:10){
 parameters[,i+3]=rep(b[i],27)
}
parameters[,14]=100000*b[1]
for(j in 1:27){
  for(i in 2:10){
    parameters[j,i+13]=parameters[j,i+12]*globalPhi[j]+100000*b[i]
  }
}
parameters[,24]=100000

#Create matrix of true parameter values, 27 rows for each of the 27 different parameter combinations N=1000
# Phi, P, Lambda, b1, b2, b3, b4, b5, b6, b7, b8, b9, b10, N1, N2, N3, N4, N5, N6, N7, N8, N9, N10, superN
parameters2<-matrix(0,nrow=27,ncol=3+10+10+1)
parameters2[,1]=globalPhi
parameters2[,2]=globalP
parameters2[,3]=globalLambda
for(i in 1:10){
 parameters2[,i+3]=rep(b[i],27)
}
parameters2[,14]=1000*b[1]
for(j in 1:27){
  for(i in 2:10){
    parameters2[j,i+13]=parameters2[j,i+12]*globalPhi[j]+1000*b[i]
  }
}
parameters2[,24]=1000
```

```{r data, echo=FALSE}
##Reads in data and creates matrices of estimates and standard errors for 4 GJSTL situation for N=1000,100000 and T=1,0.5
##{modelnum} denotes which of the 27 models (parameter combinations)

## tableESTS{GJSTL}.{modelnum} - matrix of estimates without recycled individuals for {GJSTL} and {modelnum}
## tableESTSrecycled{GJSTL}.{modelnum} - matrix of estimates with recycled individuals for {GJSTL} and {modelnum}
## tableSE{GJSTL}.{modelnum} - matrix of standard errors without recycled individuals for {GJSTL} and {modelnum}
## tableESTSrecycled{GJSTL}.{modelnum} - matrix of standard erros with recycled individuals for {GJSTL} and {modelnum}

m=1
repeat{
###GSTL1 N=1000, T=1
assign(paste("tableESTS1.",m,sep=""),read.table(paste(getwd(),"/Simulations1000/",m,".ests.txt",sep=""), sep=" "))
assign(paste("tableESTSrecycled1.",m,sep=""),read.table(paste(getwd(),"/Simulations1000/",m,".estsRECYCLED.txt",sep=""), sep=" "))
assign(paste("tableSE1.",m,sep=""),read.table(paste(getwd(),"/Simulations1000/",m,".se.txt",sep=""), sep=" "))
assign(paste("tableSErecycled1.",m,sep=""),read.table(paste(getwd(),"/Simulations1000/",m,".seRECYCLED.txt",sep=""), sep=" "))

###GSTL2 N=100000, T=1
assign(paste("tableESTS2.",m,sep=""),read.table(paste(getwd(),"/Simulations100000/",m,".ests.txt",sep=""), sep=" "))
assign(paste("tableESTSrecycled2.",m,sep=""),read.table(paste(getwd(),"/Simulations100000/",m,".estsRECYCLED.txt",sep=""), sep=" "))
assign(paste("tableSE2.",m,sep=""),read.table(paste(getwd(),"/Simulations100000/",m,".se.txt",sep=""), sep=" "))
assign(paste("tableSErecycled2.",m,sep=""),read.table(paste(getwd(),"/Simulations100000/",m,".seRECYCLED.txt",sep=""), sep=" "))

###GJSTL3 N=100000, T=0.5
#assign(paste("tableESTS3.",m,sep=""),read.table(paste(getwd(),"/Simulations100000HALF/",m,".ests.txt",sep=""), sep=" "))
#assign(paste("tableESTSrecycled3.",m,sep=""),read.table(paste(getwd(),"/Simulations100000HALF/",m,".estsRECYCLED.txt",sep=""), sep=" "))
#assign(paste("tableSE3.",m,sep=""),read.table(paste(getwd(),"/Simulations100000HALF/",m,".se.txt",sep=""), sep=" "))
#assign(paste("tableSErecycled3.",m,sep=""),read.table(paste(getwd(),"/Simulations100000HALF/",m,".seRECYCLED.txt",sep=""), sep=" "))

###GJSTL4 N=1000, T=0.5
assign(paste("tableESTS4.",m,sep=""),read.table(paste(getwd(),"/Simulations1000HALF/",m,".ests.txt",sep=""), sep=" "))
assign(paste("tableESTSrecycled4.",m,sep=""),read.table(paste(getwd(),"/Simulations1000HALF/",m,".estsRECYCLED.txt",sep=""), sep=" "))
assign(paste("tableSE4.",m,sep=""),read.table(paste(getwd(),"/Simulations1000HALF/",m,".se.txt",sep=""), sep=" "))
assign(paste("tableSErecycled4.",m,sep=""),read.table(paste(getwd(),"/Simulations1000HALF/",m,".seRECYCLED.txt",sep=""), sep=" "))
m=m+1
if(m>27){break}
}
```

```{r means_se, echo=FALSE}
#compute column means for estimates and standard errors for all parameter combinations
m=1
repeat{
###GSTL1 N=1000, T=1
assign(paste("ESTS1.",m,sep=""),colMeans(get(paste("tableESTS1.",m,sep=""))))
assign(paste("ESTSrecycled1.",m,sep=""),colMeans(get(paste("tableESTSrecycled1.",m,sep=""))))
assign(paste("SE1.",m,sep=""),colMeans(get(paste("tableSE1.",m,sep="")),na.rm=TRUE))
assign(paste("SErecycled1.",m,sep=""),colMeans(get(paste("tableSErecycled1.",m,sep="")),na.rm=TRUE))

###GSTL2 N=100000, T=1
assign(paste("ESTS2.",m,sep=""),colMeans(get(paste("tableESTS2.",m,sep=""))))
assign(paste("ESTSrecycled2.",m,sep=""),colMeans(get(paste("tableESTSrecycled2.",m,sep=""))))
assign(paste("SE2.",m,sep=""),colMeans(get(paste("tableSE2.",m,sep="")),na.rm=TRUE))
assign(paste("SErecycled2.",m,sep=""),colMeans(get(paste("tableSErecycled2.",m,sep="")),na.rm=TRUE))

###GJSTL3 N=100000, T=0.5
#assign(paste("ESTS3.",m,sep=""),colMeans(get(paste("tableESTS3.",m,sep=""))))
#assign(paste("ESTSrecycled3.",m,sep=""),colMeans(get(paste("tableESTSrecycled3.",m,sep="")),na.rm=TRUE))
#assign(paste("SE3.",m,sep=""),colMeans(get(paste("tableSE3.",m,sep=""))))
#assign(paste("SErecycled3.",m,sep=""),colMeans(get(paste("tableSErecycled3.",m,sep="")),na.rm=TRUE))

###GJSTL4 N=1000, T=0.5
assign(paste("ESTS4.",m,sep=""),colMeans(get(paste("tableESTS4.",m,sep=""))))
assign(paste("ESTSrecycled4.",m,sep=""),colMeans(get(paste("tableESTSrecycled4.",m,sep=""))))
assign(paste("SE4.",m,sep=""),colMeans(get(paste("tableSE4.",m,sep="")),na.rm=TRUE))
assign(paste("SErecycled4.",m,sep=""),colMeans(get(paste("tableSErecycled4.",m,sep="")),na.rm=TRUE))

m=m+1
if(m>27){break}
}
```


```{r sd, echo=FALSE}
#compute sd for all parameter combinations

m=1
repeat{
###GSTL1 N=1000, T=1
assign(paste("SD1.",m,sep=""),sapply(get(paste("tableESTS1.",m,sep=""))[1:24],sd))
assign(paste("SDrecycled1.",m,sep=""),sapply(get(paste("tableESTSrecycled1.",m,sep=""))[1:24],sd))

###GSTL2 N=100000, T=1
assign(paste("SD2.",m,sep=""),sapply(get(paste("tableESTS2.",m,sep=""))[1:24],sd))
assign(paste("SDrecycled2.",m,sep=""),sapply(get(paste("tableESTSrecycled2.",m,sep=""))[1:24],sd))

###GJSTL3 N=100000, T=0.5
#assign(paste("SD3.",m,sep=""),sapply(get(paste("tableESTS3.",m,sep=""))[1:24],sd))
#assign(paste("SDrecycled3.",m,sep=""),sapply(get(paste("tableESTSrecycled3.",m,sep=""))[1:24],sd))

###GJSTL4 N=1000, T=0.5
assign(paste("SD4.",m,sep=""),sapply(get(paste("tableESTS4.",m,sep=""))[1:24],sd))
assign(paste("SDrecycled4.",m,sep=""),sapply(get(paste("tableESTSrecycled4.",m,sep=""))[1:24],sd))

m=m+1
if(m>27){break}
}
```

```{r RMSE, echo=FALSE}
#compute MSE for all parameter combinations
ColCalcRMSE<-function(A,b){
  RMSE=vector(length=length(b))
  for(i in 1:length(b)){
    RMSE[i]=sqrt(mean((A[,i]-b[i])^2))
  }
  RMSE
}


m=1
repeat{
###GSTL1 N=1000, T=1
assign(paste("RMSE1.",m,sep=""),ColCalcRMSE(get(paste("tableESTS1.",m,sep=""))[1:24],parameters2[m,]))
assign(paste("RMSErecycled1.",m,sep=""),ColCalcRMSE(get(paste("tableESTSrecycled1.",m,sep=""))[1:24],parameters2[m,]))

###GSTL2 N=100000, T=1
assign(paste("RMSE2.",m,sep=""),ColCalcRMSE(get(paste("tableESTS2.",m,sep=""))[1:24],parameters[m,]))
assign(paste("RMSErecycled2.",m,sep=""),ColCalcRMSE(get(paste("tableESTSrecycled2.",m,sep=""))[1:24],parameters[m,]))

###GJSTL3 N=100000, T=0.5
#assign(paste("RMSE3.",m,sep=""),ColCalcRMSE(get(paste("tableESTS3.",m,sep=""))[1:24],parameters[m,]))
#assign(paste("RMSErecycled3.",m,sep=""),ColCalcRMSE(get(paste("tableESTSrecycled3.",m,sep=""))[1:24],parameters[m,]))

###GJSTL4 N=1000, T=0.5
assign(paste("RMSE4.",m,sep=""),ColCalcRMSE(get(paste("tableESTS4.",m,sep=""))[1:24],parameters[m,]))
assign(paste("RMSErecycled4.",m,sep=""),ColCalcRMSE(get(paste("tableESTSrecycled4.",m,sep=""))[1:24],parameters[m,]))

m=m+1
if(m>27){break}
}
```


```{r relativebias, echo=FALSE}
#compute bias for all parameter combinations
m=1
repeat{
###GSTL1 N=1000, T=1
assign(paste("BIAS1.",m,sep=""),(get(paste("ESTS1.",m,sep=""))[1:24]-parameters2[m,]) /parameters2[m,])
assign(paste("BIASrecycled1.",m,sep=""),(get(paste("ESTSrecycled1.",m,sep=""))[1:24]-parameters2[m,])/parameters2[m,])


###GSTL2 N=100000, T=1
assign(paste("BIAS2.",m,sep=""),(get(paste("ESTS2.",m,sep=""))[1:24]-parameters[m,])/parameters[m,])
assign(paste("BIASrecycled2.",m,sep=""),(get(paste("ESTSrecycled2.",m,sep=""))[1:24]-parameters[m,])/parameters[m,])


###GJSTL3 N=100000, T=0.5
#assign(paste("BIAS3.",m,sep=""),(get(paste("ESTS3.",m,sep=""))[1:24]-parameters[m,])/parameters[m,])
#assign(paste("BIASrecycled3.",m,sep=""),(get(paste("ESTSrecycled3.",m,sep=""))[1:24]-parameters[m,])/parameters[m,])

###GJSTL4 N=1000, T=0.5
assign(paste("BIAS4.",m,sep=""),(get(paste("ESTS4.",m,sep=""))[1:24]-parameters2[m,])/parameters2[m,])
assign(paste("BIASrecycled4.",m,sep=""),(get(paste("ESTSrecycled4.",m,sep=""))[1:24]-parameters2[m,])/parameters2[m,])

m=m+1
if(m>27){break}
}
```

The mean relative bias of the survival estimates were biased for some parameter combinations of survival, capture, and tag retention probabilities. As an example, boxplots of survival estimates for data with super-population size N=1000 and 100\% double tagging are provided (Figure 1). Boxplots of survival estimates for other super-population sizes and double-tagging rates are provided in the appendix (Figures A1-A4). Although there was bias in the survival estimates for several of the parameter combinations, the bias was similar between the analysis with and the analysis without the recycled individuals included for both super-population sizes ($N=1000$ and $100000$) and for both double-tagging rates ($T_2=0.5,1$).  In fact, the differences in relative bias due to recycled individuals for the parameters $\phi$, $p$ and $\lambda$ was small (<0.01) for all 108 parameter combinations considered. In general, the SE, SD and RMSE of the estimates of $\phi$, $p$ and $\lambda$ were similar for both the analysis with and without recycled individuals for the parameter combinations considered. It seems that, in general, the treatment of recycled individuals has little effect, if any, on the accuracy of the JSTL estimators for survival, capture, and tag-retention probabilities. Boxplots of capture and tag retention estimates for all models can also be found in the Appendix (Figures A5-A12).    

Results were similar for both the super-population sizes of 1000 and 100000 for all parameter combinations of survival, capture, and tag retention probabilities. There is slightly more bias due to recycled individuals for parameter combinations where the probability of double tagging ($T_2$) is only 0.5, compared to the parameter combinations where all individuals are double tagged. As an example, relative bias of the parameters are presented for the parameter combination where $\phi=0.9, p=0.9$ and $\lambda=0.2$ for both the analysis with and without recycled individuals for varying population size and double-tagging probabilities (Table 1).  


```{r Figure1_survival_GJSTL1, echo=FALSE, warning=FALSE}
m=1
repeat{
assign(paste("tableESTS.",m,sep=""),read.table(paste("~/Documents/GitHub/Recycled-Individuals/Simulations1000/",m,".ests.txt",sep=""), sep=" "))
assign(paste("tableESTSrecycled.",m,sep=""),read.table(paste("~/Documents/GitHub/Recycled-Individuals/Simulations1000/",m,".estsRECYCLED.txt",sep=""), sep=" "))
m=m+1
if(m>27){break}
}

par(mfrow=c(3,3),oma=c(3,5,2,4),mai=c(0.1,0.1,0.1,0.1))

#1
combine <- list(tableESTSrecycled.27[,1],tableESTS.27[,1],tableESTSrecycled.24[,1],tableESTS.24[,1],tableESTSrecycled.21[,1],tableESTS.21[,1])  # create a list of vectors to be bound 
max.length <- max(sapply(combine, length)) 
matrix=do.call(cbind, lapply(combine, function(.vec){ 
     c(.vec, rep(NA, max.length - length(.vec))) 
}))

boxplot(matrix, col=(c(colors[2],colors[3],colors[2],colors[3], colors[2],colors[3])),ylim=c(0,1), axes=FALSE)
box()
axis(side=2, las=2, cex=0.7) 
abline(h=0.2)
mtext(side = 3, outer=FALSE, text=bquote(paste(lambda," = ",0.2)), line = 1, cex=0.7)

#2
combine <- list(tableESTSrecycled.26[,1],tableESTS.26[,1],tableESTSrecycled.23[,1],tableESTS.23[,1],tableESTSrecycled.20[,1],tableESTS.20[,1])  # create a list of vectors to be bound 
max.length <- max(sapply(combine, length)) 
matrix=do.call(cbind, lapply(combine, function(.vec){ 
     c(.vec, rep(NA, max.length - length(.vec))) 
}))

boxplot(matrix, col=(c(colors[2],colors[3],colors[2],colors[3], colors[2],colors[3])),ylim=c(0,1), axes=FALSE)
box()
abline(h=0.2)
mtext(side = 3, outer=FALSE, text=bquote(paste(lambda," = ",0.5)), line = 1, cex=0.7)

#3
combine <- list(tableESTSrecycled.25[,1],tableESTS.25[,1],tableESTSrecycled.22[,1],tableESTS.22[,1],tableESTSrecycled.19[,1],tableESTS.19[,1])  # create a list of vectors to be bound 
max.length <- max(sapply(combine, length)) 
matrix=do.call(cbind, lapply(combine, function(.vec){ 
     c(.vec, rep(NA, max.length - length(.vec))) 
}))

boxplot(matrix, col=(c(colors[2],colors[3],colors[2],colors[3], colors[2],colors[3])),ylim=c(0,1), axes=FALSE)
box()
abline(h=0.2)
mtext(side = 3, outer=FALSE, text=bquote(paste(lambda," = ",0.9)), line = 1, cex=0.7)
mtext(side = 4, las=1, outer=FALSE, text=bquote(paste(phi," = ",0.2)), line = 1, cex=0.7)

#4
combine <- list(tableESTSrecycled.18[,1],tableESTS.18[,1],tableESTSrecycled.15[,1],tableESTS.15[,1],tableESTSrecycled.12[,1],tableESTS.12[,1])  # create a list of vectors to be bound 
max.length <- max(sapply(combine, length)) 
matrix=do.call(cbind, lapply(combine, function(.vec){ 
     c(.vec, rep(NA, max.length - length(.vec))) 
}))

boxplot(matrix, col=(c(colors[2],colors[3],colors[2],colors[3], colors[2],colors[3])),ylim=c(0,1), axes=FALSE)
box()
axis(side=2, las=2, cex=0.7) 
abline(h=0.5)

#5
combine <- list(tableESTSrecycled.17[,1],tableESTS.17[,1],tableESTSrecycled.14[,1],tableESTS.14[,1],tableESTSrecycled.11[,1],tableESTS.11[,1])  # create a list of vectors to be bound 
max.length <- max(sapply(combine, length)) 
matrix=do.call(cbind, lapply(combine, function(.vec){ 
     c(.vec, rep(NA, max.length - length(.vec))) 
}))

boxplot(matrix, col=(c(colors[2],colors[3],colors[2],colors[3], colors[2],colors[3])),ylim=c(0,1), axes=FALSE)
box()
abline(h=0.5)

#6
combine <- list(tableESTSrecycled.16[,1],tableESTS.16[,1],tableESTSrecycled.13[,1],tableESTS.13[,1],tableESTSrecycled.10[,1],tableESTS.10[,1])  # create a list of vectors to be bound 
max.length <- max(sapply(combine, length)) 
matrix=do.call(cbind, lapply(combine, function(.vec){ 
     c(.vec, rep(NA, max.length - length(.vec))) 
}))

boxplot(matrix, col=(c(colors[2],colors[3],colors[2],colors[3], colors[2],colors[3])),ylim=c(0,1), axes=FALSE)
box()
abline(h=0.5)
mtext(side = 4, las=1, outer=FALSE, text=bquote(paste(phi," = ",0.5)), line = 1, cex=0.7)

#7
combine <- list(tableESTSrecycled.9[,1],tableESTS.9[,1],tableESTSrecycled.6[,1],tableESTS.6[,1],tableESTSrecycled.3[,1],tableESTS.3[,1])  # create a list of vectors to be bound 
max.length <- max(sapply(combine, length)) 
matrix=do.call(cbind, lapply(combine, function(.vec){ 
     c(.vec, rep(NA, max.length - length(.vec))) 
}))

boxplot(matrix, col=(c(colors[2],colors[3],colors[2],colors[3], colors[2],colors[3])),ylim=c(0,1), axes=FALSE)
box()
axis(side=2, las=2, cex=0.7) 
abline(h=0.9)
mtext(text=bquote(paste("p=0.2","       ","p=0.5", "       ","p=0.9")), side = 1, line = 0.5, cex=0.7)


#8
combine <- list(tableESTSrecycled.8[,1],tableESTS.8[,1],tableESTSrecycled.5[,1],tableESTS.5[,1],tableESTSrecycled.2[,1],tableESTS.2[,1])  # create a list of vectors to be bound 
max.length <- max(sapply(combine, length)) 
matrix=do.call(cbind, lapply(combine, function(.vec){ 
     c(.vec, rep(NA, max.length - length(.vec))) 
}))

boxplot(matrix, col=(c(colors[2],colors[3],colors[2],colors[3], colors[2],colors[3])),ylim=c(0,1), axes=FALSE)
box()
abline(h=0.9)
mtext(text=bquote(paste("p=0.2","       ","p=0.5", "       ","p=0.9")), side = 1, line = 0.5, cex=0.7)

#9
combine <- list(tableESTSrecycled.7[,1],tableESTS.7[,1],tableESTSrecycled.4[,1],tableESTS.4[,1],tableESTSrecycled.1[,1],tableESTS.1[,1])  # create a list of vectors to be bound 
max.length <- max(sapply(combine, length)) 
matrix=do.call(cbind, lapply(combine, function(.vec){ 
     c(.vec, rep(NA, max.length - length(.vec))) 
}))

boxplot(matrix, col=(c(colors[2],colors[3],colors[2],colors[3], colors[2],colors[3])),ylim=c(0,1), axes=FALSE)
box()
abline(h=0.9)
mtext(side = 4, las=1, outer=FALSE, text=bquote(paste(phi," = ",0.9)), line = 1, cex=0.7)
mtext(text=bquote(paste("p=0.2","       ","p=0.5", "       ","p=0.9")), side = 1, line = 0.5, cex=0.7)


mtext(side = 2, outer=TRUE, "Survival Estimates", line = 2, cex=0.7)

par(fig = c(0, 1, 0, 1), oma = c(0, 0, 0, 0), mar = c(0, 0, 0, 0), new = TRUE)
plot(0, 0, type = "n", bty = "n", xaxt = "n", yaxt = "n")
legend("bottom", c("With Recycled Indls","Without Recycled Indls"), xpd = TRUE, horiz = TRUE, inset = c(0, 0), bty = "n", pch = c(15,15), col = c(colors[2],colors[3]), cex = 1)
```

> \textsc{Figure 1:} \textsl{Simulation results for data with super-population size $N=1000$ with 100\% double-tagging for different tag retention probabilities ($\lambda=0.2,0.5,0.9$), survival probabilities ($\phi=0.2,0.5,0.9$), and different capture probabilities ($p=0.2,0.5,0.9$) using the JSTL model from a ten-sample-time study. Boxplots of the estimates of $\phi$ for the model analyzed with and without the recycled individuals are provided. The black line indicates the true value of $\phi$ used to simulate the data for each model.}


```{r Table2_Model3,results='asis',echo=FALSE, cache=TRUE}
library(xtable)
parameters1=c(0.9,0.9,0.2,100000,10000,19000,27100,34390,40951, 46855.9,52170.31,56953.28,61257.95,65132.16)
parameters2=c(0.9,0.9,0.2,1000,100,190,271,343.9,409.51,468.559,521.7031,569.5328,612.5795,651.3216)  
table<-matrix(0, nrow=15, ncol=12)

#GJSTL N=1000 frac=1
assign(paste("tableESTSrecycled.GJSTL1.",3,sep=""),read.table(paste("~/Documents/GitHub/Recycled-Individuals/Simulations1000/",3,".estsRECYCLED.txt",sep=""), sep=" "))
assign(paste("tableESTS.GJSTL1.",3,sep=""),read.table(paste("~/Documents/GitHub/Recycled-Individuals/Simulations1000/",3,".ests.txt",sep=""), sep=" "))
#table[1,1]=nrow(tableESTSrecycled.GJSTL1.3)
#table[1,2]=nrow(tableESTS.GJSTL1.3)
tableESTSrecycled.GJSTL1.3=colMeans(tableESTSrecycled.GJSTL1.3)
tableESTS.GJSTL1.3=colMeans(tableESTS.GJSTL1.3)

table[2:15,1]=(tableESTSrecycled.GJSTL1.3[c(1:3,24,14:23)]-parameters2)/parameters2
table[2:15,2]=(tableESTS.GJSTL1.3[c(1:3,24,14:23)]-parameters2)/parameters2
table[2:15,3]=table[2:15,1]-table[2:15,2]

#GJSTL4 N=1000 frac=0.5
assign(paste("tableESTSrecycled.GJSTL4.",3,sep=""),read.table(paste("~/Documents/GitHub/Recycled-Individuals/Simulations1000HALF/",3,".estsRECYCLED.txt",sep=""), sep=" "))
assign(paste("tableESTS.GJSTL4.",3,sep=""),read.table(paste("~/Documents/GitHub/Recycled-Individuals/Simulations1000HALF/",3,".ests.txt",sep=""), sep=" "))
tableESTSrecycled.GJSTL4.3=colMeans(tableESTSrecycled.GJSTL4.3)
tableESTS.GJSTL4.3=colMeans(tableESTS.GJSTL4.3)

table[2:15,4]=(tableESTSrecycled.GJSTL4.3[c(1:3,24,14:23)]-parameters2)/parameters2
table[2:15,5]=(tableESTS.GJSTL4.3[c(1:3,24,14:23)]-parameters2)/parameters2
table[2:15,6]=table[2:15,1]-table[2:15,2]


#GJSTL2 N=100000 frac=1
assign(paste("tableESTSrecycled.GJSTL2.",3,sep=""),read.table(paste("~/Documents/GitHub/Recycled-Individuals/Simulations100000/",3,".estsRECYCLED.txt",sep=""), sep=" "))
assign(paste("tableESTS.GJSTL2.",3,sep=""),read.table(paste("~/Documents/GitHub/Recycled-Individuals/Simulations100000/",3,".ests.txt",sep=""), sep=" "))
#table[1,7]=nrow(tableESTSrecycled.GJSTL2.3)
#table[1,8]=nrow(tableESTS.GJSTL2.3)
tableESTSrecycled.GJSTL2.3=colMeans(tableESTSrecycled.GJSTL2.3)
tableESTS.GJSTL2.3=colMeans(tableESTS.GJSTL2.3)

table[2:15,7]=(tableESTSrecycled.GJSTL2.3[c(1:3,24,14:23)]-parameters1)/parameters1
table[2:15,8]=(tableESTS.GJSTL2.3[c(1:3,24,14:23)]-parameters1)/parameters1
table[2:15,9]=table[2:15,7]-table[2:15,8]

#GJSTL3 N=100000 frac=0.5
assign(paste("tableESTSrecycled.GJSTL3.",3,sep=""),read.table(paste("~/Documents/GitHub/Recycled-Individuals/Simulations100000HALF/",3,".estsRECYCLED.txt",sep=""), sep=" "))
assign(paste("tableESTS.GJSTL3.",3,sep=""),read.table(paste("~/Documents/GitHub/Recycled-Individuals/Simulations100000HALF/",3,".ests.txt",sep=""), sep=" "))
#table[1,10]=nrow(tableESTSrecycled.GJSTL3.3)
#table[1,11]=nrow(tableESTS.GJSTL3.3)
tableESTSrecycled.GJSTL3.3=colMeans(tableESTSrecycled.GJSTL3.3)
tableESTS.GJSTL3.3=colMeans(tableESTS.GJSTL3.3)

table[2:15,10]=(tableESTSrecycled.GJSTL3.3[c(1:3,24,14:23)]-parameters1)/parameters1
table[2:15,11]=(tableESTS.GJSTL3.3[c(1:3,24,14:23)]-parameters1)/parameters1
table[2:15,12]=table[2:15,10]-table[2:15,11]


rownames(table)<-c("sim","$\\phi$","p","$\\lambda$","N","$N_1$","$N_2$","$N_3$","$N_4$", "$N_5$", "$N_6$", "$N_7$", "$N_8$", "$N_9$", "$N_{10}$")
colnames(table)<-c(rep(c("$R$","$R'$","diff"),4))
#N=1000
#frac=1   frac=0.5
#N=100000
#frac=1   frac=0.5
for(i in 2:15){
  for (j in 1:12){
    if(round(table[i,j],1)==0){
      table[i,j]=0
    }
  }
}
table=table[2:5,c(1,2,4,5,7,8,10,11)]

#print(xtable(table, digits=2), comment=FALSE, sanitize.colnames.function = identity, sanitize.rownames.function = identity)
#library(knitr)

#kable(round(table,2), format="markdown")
```
\ 
&nbsp;

> \textsc{Table 1:} \textsl{Simulation results for data with high survival probability ($\phi=0.9$), high capture probability ($p=0.9$), and low tag retention ($\lambda=0.2$)  for different super-populations sizes ($N=1000,100000$) and different tag retention probabilities ($T_2=0.5,1$) using the JSTL model from a ten-sample-time study. The mean relative bias of the parameters from the model analyzed with ($R$) and without ($R'$) the recycled individuals is provided.}

\begin{table}[ht]
\centering
\begin{tabular}{rcccccccc}
  \hline
  & \multicolumn{8}{l}{Population Size and Percent Double Tagged} \\
  \cline{2-9}
  & \multicolumn{4}{l}{N=1000} & \multicolumn{4}{l}{N=100000} \\
  \cline {2-9}
  & $T_2=1$ && $T_2=0.5$ && $T_2=1$ && $T_2=0.5$ &  \\ 
  \cline {2-9}
  & $R$ & $R'$ & $R$ & $R'$ & $R$ & $R'$ & $R$ & $R'$ \\ 
  \hline
$\phi$ & 0.00 & 0.00 & 0.06 & 0.05 & 0.00 & 0.00 & 0.11 & 0.10 \\ 
  p & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 \\ 
  $\lambda$ & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & -0.09 & -0.08 \\ 
  N & 1.98 & 0.00 & 2.13 & 0.00 & 1.98 & 0.00 & 2.12 & 0.00 \\ 
   \hline
\end{tabular}
\end{table}

\ 
&nbsp;

The estimate of super-population size ($\hat{N}$) was computed as $\hat{N}=n_{\text{obs}}/{(1-\hat{P}_0)}$, where $\hat{P}_0$ was the estimated probability of never being seen. In the scenarios where many recycled individuals are being recaptured and considered as "new" individuals, $n_{\text{obs}}$ was larger than it should be and thus, $\hat{N}$ was biased upwards. This bias was corrected in the analysis without the recycled individuals considered. The relative bias in the super-population size ($\hat{N}$) due to recycled individuals was the highest in the scenario of high survival rates ($\phi=0.9$), high capture rates ($p=0.9$) and low tag retention rates ($\lambda=0.2$), as predicted (Figure 2, Table 1). The relative bias was small for all scenarios where tag retention is high, but relative bias increases as tag retention decreases.  The relative bias in $\hat{N}$ decreases as capture probabilities decrease, but recycled individuals appear to still be having some effect on the estimates even when capture probabilities are low  ($p=0.2$). The relative bias in $\hat{N}$ is high for scenarios where survival probabilities are high, and decreases as survival probabilities decreases. In all scenarios where survival was low ($\phi=0.2$) individuals are unlikely to survive long enough to be able to be tagged, lose tag(s) and be recaptured as a "new" individual. When survival is low, the relative bias due to the recycled individuals is small (less than 0.15) and hence not shown in Figure 2. SE, SD, and RMSE  of $\hat{N}$ varied, but remained similar between the analysis with and without recycled individuals included, across all scenarios. 
   

```{r Figure2_N, fig.height=2.5, echo=FALSE, warning=FALSE}
m=1
repeat{
assign(paste("tableESTS.",m,sep=""),read.table(paste("~/Documents/GitHub/Recycled-Individuals/Simulations100000/",m,".ests.txt",sep=""), sep=" "))
assign(paste("tableESTSrecycled.",m,sep=""),read.table(paste("~/Documents/GitHub/Recycled-Individuals/Simulations100000/",m,".estsRECYCLED.txt",sep=""), sep=" "))
m=m+1
if(m>27){break}
}

par(mfrow=c(2,3),oma=c(3,5,2,4),mai=c(0.1,0.1,0.1,0.1))

#1
combine <- list(tableESTSrecycled.1[,24],tableESTS.1[,24],tableESTSrecycled.2[,24],tableESTS.2[,24],tableESTSrecycled.3[,24],tableESTS.3[,24])  # create a list of vectors to be bound 
max.length <- max(sapply(combine, length)) 
matrix=do.call(cbind, lapply(combine, function(.vec){ 
     c(.vec, rep(NA, max.length - length(.vec))) 
}))

meanmatrix=colMeans(matrix, na.rm=TRUE)
barplot(c((meanmatrix[1]-100000)/100000-(meanmatrix[2]-100000)/100000,(meanmatrix[3]-100000)/100000-(meanmatrix[4]-100000)/100000, (meanmatrix[5]-100000)/100000-(meanmatrix[6]-100000)/100000), col=colors[3:1],ylim=c(0,2.15), axes=FALSE)
box()
axis(side=2, las=2, cex=0.7) 
mtext(side = 3, outer=FALSE, text=expression(p==0.9), line = 0.5, cex=0.7)
mtext(text=bquote(paste(lambda,"=0.9","       ",lambda,"=0.5", "       ",lambda,"=0.2")), side = 1, line = 0, cex=0.7)

#2
combine <- list(tableESTSrecycled.4[,24],tableESTS.4[,24],tableESTSrecycled.5[,24],tableESTS.5[,24],tableESTSrecycled.6[,24],tableESTS.6[,24])  # create a list of vectors to be bound 
max.length <- max(sapply(combine, length)) 
matrix=do.call(cbind, lapply(combine, function(.vec){ 
     c(.vec, rep(NA, max.length - length(.vec))) 
}))

meanmatrix=colMeans(matrix, na.rm=TRUE)
barplot(c((meanmatrix[1]-100000)/100000-(meanmatrix[2]-100000)/100000,(meanmatrix[3]-100000)/100000-(meanmatrix[4]-100000)/100000, (meanmatrix[5]-100000)/100000-(meanmatrix[6]-100000)/100000), col=colors[3:1],ylim=c(0,2.15), axes=FALSE)
box()
mtext(side = 3, outer=FALSE, text=expression(p==0.5), line = 0.5, cex=0.7)
mtext(text=bquote(paste(lambda,"=0.9","       ",lambda,"=0.5", "       ",lambda,"=0.2")), side = 1, line = 0, cex=0.7)

#3
combine <- list(tableESTSrecycled.7[,24],tableESTS.7[,24],tableESTSrecycled.8[,24],tableESTS.8[,24],tableESTSrecycled.9[,24],tableESTS.9[,24])  # c4reate a list of vectors to be bound 
max.length <- max(sapply(combine, length)) 
matrix=do.call(cbind, lapply(combine, function(.vec){ 
     c(.vec, rep(NA, max.length - length(.vec))) 
}))

meanmatrix=colMeans(matrix, na.rm=TRUE)
barplot(c((meanmatrix[1]-100000)/100000-(meanmatrix[2]-100000)/100000,(meanmatrix[3]-100000)/100000-(meanmatrix[4]-100000)/100000, (meanmatrix[5]-100000)/100000-(meanmatrix[6]-100000)/100000), col=colors[3:1],ylim=c(0,2.15), axes=FALSE)
box()
mtext(side = 3, outer=FALSE, text=expression(p==0.2), line = 0.5, cex=0.7)
mtext(side = 4, las=1, outer=FALSE, text=expression(phi==0.9), line = 1, cex=0.7)
mtext(text=bquote(paste(lambda,"=0.9","       ",lambda,"=0.5", "       ",lambda,"=0.2")), side = 1, line = 0, cex=0.7)

#4
combine <- list(tableESTSrecycled.10[,24],tableESTS.10[,24],tableESTSrecycled.11[,24],tableESTS.11[,24],tableESTSrecycled.12[,24],tableESTS.12[,24])  # create a list of vectors to be bound 
max.length <- max(sapply(combine, length)) 
matrix=do.call(cbind, lapply(combine, function(.vec){ 
     c(.vec, rep(NA, max.length - length(.vec))) 
}))

meanmatrix=colMeans(matrix, na.rm=TRUE)
barplot(c((meanmatrix[1]-100000)/100000-(meanmatrix[2]-100000)/100000,(meanmatrix[3]-100000)/100000-(meanmatrix[4]-100000)/100000, (meanmatrix[5]-100000)/100000-(meanmatrix[6]-100000)/100000), col=colors[3:1],ylim=c(0,2.15), axes=FALSE)
box()
axis(side=2, las=2, cex=0.7) 
mtext(text=bquote(paste(lambda,"=0.9","       ",lambda,"=0.5", "       ",lambda,"=0.2")), side = 1, line = 0, cex=0.7)

#5
combine <- list(tableESTSrecycled.13[,24],tableESTS.13[,24],tableESTSrecycled.14[,24],tableESTS.14[,24],tableESTSrecycled.15[,24],tableESTS.15[,24])  # create a list of vectors to be bound 
max.length <- max(sapply(combine, length)) 
matrix=do.call(cbind, lapply(combine, function(.vec){ 
     c(.vec, rep(NA, max.length - length(.vec))) 
}))

meanmatrix=colMeans(matrix, na.rm=TRUE)
barplot(c((meanmatrix[1]-100000)/100000-(meanmatrix[2]-100000)/100000,(meanmatrix[3]-100000)/100000-(meanmatrix[4]-100000)/100000, (meanmatrix[5]-100000)/100000-(meanmatrix[6]-100000)/100000), col=colors[3:1],ylim=c(0,2.15), axes=FALSE)
box()
mtext(text=bquote(paste(lambda,"=0.9","       ",lambda,"=0.5", "       ",lambda,"=0.2")), side = 1, line = 0, cex=0.7)

#6
combine <- list(tableESTSrecycled.16[,24],tableESTS.16[,24],tableESTSrecycled.17[,24],tableESTS.17[,24],tableESTSrecycled.18[,24],tableESTS.18[,24])  # create a list of vectors to be bound 
max.length <- max(sapply(combine, length)) 
matrix=do.call(cbind, lapply(combine, function(.vec){ 
     c(.vec, rep(NA, max.length - length(.vec))) 
}))

meanmatrix=colMeans(matrix, na.rm=TRUE)
barplot(c((meanmatrix[1]-100000)/100000-(meanmatrix[2]-100000)/100000,(meanmatrix[3]-100000)/100000-(meanmatrix[4]-100000)/100000, (meanmatrix[5]-100000)/100000-(meanmatrix[6]-100000)/100000), col=colors[3:1],ylim=c(0,2.15), axes=FALSE)
box()
mtext(side = 4, las=1, outer=FALSE, text=expression(phi==0.5), line = 1, cex=0.7)
mtext(text=bquote(paste(lambda,"=0.9","       ",lambda,"=0.5", "       ",lambda,"=0.2")), side = 1, line = 0, cex=0.7)

#7
# combine <- list(tableESTSrecycled.19[,24],tableESTS.19[,24],tableESTSrecycled.20[,24],tableESTS.20[,24],tableESTSrecycled.21[,24],tableESTS.21[,24])  # create a list of vectors to be bound 
# max.length <- max(sapply(combine, length)) 
# matrix=do.call(cbind, lapply(combine, function(.vec){ 
#      c(.vec, rep(NA, max.length - length(.vec))) 
# }))
# 
# meanmatrix=colMeans(matrix, na.rm=TRUE)
# barplot(c((meanmatrix[1]-100000)/100000-(meanmatrix[2]-100000)/100000,(meanmatrix[3]-100000)/100000-(meanmatrix[4]-100000)/100000, (meanmatrix[5]-100000)/100000-(meanmatrix[6]-100000)/100000), col=colors[c(5,7,9)],ylim=c(0,2.15), axes=FALSE)
# box()
# axis(side=2, las=2, cex=0.7) 
# mtext(text=bquote(paste(lambda,"=0.9","       ",lambda,"=0.5", "       ",lambda,"=0.2")), side = 1, line = 0, cex=0.7)

#8
# combine <- list(tableESTSrecycled.22[,24],tableESTS.22[,24],tableESTSrecycled.23[,24],tableESTS.23[,24],tableESTSrecycled.24[,24],tableESTS.24[,24])  # create a list of vectors to be bound 
# max.length <- max(sapply(combine, length)) 
# matrix=do.call(cbind, lapply(combine, function(.vec){ 
#      c(.vec, rep(NA, max.length - length(.vec))) 
# }))
# 
# meanmatrix=colMeans(matrix, na.rm=TRUE)
# barplot(c((meanmatrix[1]-100000)/100000-(meanmatrix[2]-100000)/100000,(meanmatrix[3]-100000)/100000-(meanmatrix[4]-100000)/100000, (meanmatrix[5]-100000)/100000-(meanmatrix[6]-100000)/100000), col=colors[c(5,7,9)],ylim=c(0,2.15), axes=FALSE)
# box()
# mtext(text=bquote(paste(lambda,"=0.9","       ",lambda,"=0.5", "       ",lambda,"=0.2")), side = 1, line = 0, cex=0.7)

#9
# combine <- list(tableESTSrecycled.25[,24],tableESTS.25[,24],tableESTSrecycled.26[,24],tableESTS.26[,24],tableESTSrecycled.27[,24],tableESTS.27[,24])  # create a list of vectors to be bound 
# max.length <- max(sapply(combine, length)) 
# matrix=do.call(cbind, lapply(combine, function(.vec){ 
#      c(.vec, rep(NA, max.length - length(.vec))) 
# }))
# 
# 
# meanmatrix=colMeans(matrix, na.rm=TRUE)
# barplot(c((meanmatrix[1]-100000)/100000-(meanmatrix[2]-100000)/100000,(meanmatrix[3]-100000)/100000-(meanmatrix[4]-100000)/100000, (meanmatrix[5]-100000)/100000-(meanmatrix[6]-100000)/100000), col=colors[c(5,7,9)],ylim=c(0,2.15), axes=FALSE)
# box()
# mtext(side = 4, las=1, outer=FALSE, text=expression(phi==0.2), line = 1, cex=0.7)
# mtext(text=bquote(paste(lambda,"=0.9","       ",lambda,"=0.5", "       ",lambda,"=0.2")), side = 1, line = 0, cex=0.7)


mtext(side = 2, outer=TRUE, "Relative Bias of Super-Population Size", line = 3, cex=0.7)
mtext(side = 2, outer=TRUE, "Estimates Due to Recycled Individuals", line = 2, cex=0.7)


#par(fig = c(0, 1, 0, 1), oma = c(0, 0, 0, 0), mar = c(0, 0, 0, 0), new = TRUE)
#plot(0, 0, type = "n", bty = "n", xaxt = "n", yaxt = "n")
#legend("bottom", c(expression(lambda==0.9),expression(lambda==0.5), expression(lambda==0.2)), xpd = TRUE, horiz = TRUE, inset = c(0, 0), bty = "n", pch = c(15,15,15), col = c(colors[c(5,7,9)]), cex = 1.25)
```

> \textsc{Figure 2:} \textsl{Simulation results for data with super-population size $N=100 000$ with 100\% double-tagging for different tag retention probabilities ($\lambda=0.2,0.5,0.9$), survival probabilities ($\phi=0.2,0.5,0.9$), and different capture probabilities ($p=0.2,0.5,0.9$) using the JSTL model from a ten-sample-time study. The difference in mean relative bias of the super-population estimate ($\hat{N}$) between the model analyzed with and without the recycled individuals is provided.} 


```{r Figure3_N_k, echo=FALSE, fig.height=2}

m=3
repeat{
assign(paste("tableESTS10.",m,sep=""),read.table(paste("~/Documents/GitHub/Recycled-Individuals/Simulations1000/",m,".ests.txt",sep=""), sep=" "))
assign(paste("tableESTS10recycled.",m,sep=""),read.table(paste("~/Documents/GitHub/Recycled-Individuals/Simulations1000/",m,".estsRECYCLED.txt",sep=""), sep=" "))
assign(paste("tableESTS7.",m,sep=""),read.table(paste("~/Documents/GitHub/Recycled-Individuals/Simulations1000time7/",m,".ests.txt",sep=""), sep=" "))
assign(paste("tableESTS7recycled.",m,sep=""),read.table(paste("~/Documents/GitHub/Recycled-Individuals/Simulations1000time7/",m,".estsRECYCLED.txt",sep=""), sep=" "))
assign(paste("tableESTS5.",m,sep=""),read.table(paste("~/Documents/GitHub/Recycled-Individuals/Simulations1000time5/",m,".ests.txt",sep=""), sep=" "))
assign(paste("tableESTS5recycled.",m,sep=""),read.table(paste("~/Documents/GitHub/Recycled-Individuals/Simulations1000time5/",m,".estsRECYCLED.txt",sep=""), sep=" "))
m=m+3
if(m>10){break}
}


par(mfrow=c(1,3),oma=c(3,5,2,4),mai=c(0.1,0.1,0.1,0.1))

#1
combine <- list(tableESTS10recycled.3[,24],tableESTS10.3[,24], tableESTS7recycled.3[,18],tableESTS7.3[,18], tableESTS5recycled.3[,14],tableESTS5.3[,14])  # create a list of vectors to be bound 
max.length <- max(sapply(combine, length)) 
matrix=do.call(cbind, lapply(combine, function(.vec){ 
  c(.vec, rep(NA, max.length - length(.vec))) 
}))

boxplot(matrix, col=(c(colors[2],colors[3],colors[2],colors[3], colors[2],colors[3])),ylim=c(500,4000), axes=FALSE)
box()
axis(side=2, las=2, cex=0.7) 
mtext(side = 3, outer=FALSE, text=bquote(paste("p = ",0.9)), line = 0.5, cex=0.7)
mtext(text=bquote(paste("k=10","         ","k=7", "         ","k=5")), side = 1, line = 0, cex=0.7)
mtext(side = 2, outer=TRUE, "Super-Population Size Estimates", line = 2.5, cex=0.7)

#2
combine <- list(tableESTS10recycled.6[,24],tableESTS10.6[,24], tableESTS7recycled.6[,18],tableESTS7.6[,18], tableESTS5recycled.6[,14],tableESTS5.6[,14])  # create a list of vectors to be bound 
max.length <- max(sapply(combine, length)) 
matrix=do.call(cbind, lapply(combine, function(.vec){ 
  c(.vec, rep(NA, max.length - length(.vec))) 
}))

boxplot(matrix, col=(c(colors[2],colors[3],colors[2],colors[3], colors[2],colors[3])),ylim=c(500,4000), axes=FALSE)
box()
#axis(side=2, las=2, cex=0.7) 
mtext(side = 3, outer=FALSE, text=bquote(paste("p = ",0.5)), line = 0.5, cex=0.7)
mtext(text=bquote(paste("k=10","         ","k=7", "         ","k=5")), side = 1, line = 0, cex=0.7)

#3
combine <- list(tableESTS10recycled.9[,24],tableESTS10.9[,24], tableESTS7recycled.9[,18],tableESTS7.9[,18], tableESTS5recycled.9[,14],tableESTS5.9[,14])  # create a list of vectors to be bound 
max.length <- max(sapply(combine, length)) 
matrix=do.call(cbind, lapply(combine, function(.vec){ 
  c(.vec, rep(NA, max.length - length(.vec))) 
}))

boxplot(matrix, col=(c(colors[2],colors[3],colors[2],colors[3], colors[2],colors[3])),ylim=c(500,4000), axes=FALSE)
box() 
mtext(side = 3, outer=FALSE, text=bquote(paste("p = ",0.2)), line = 0.5, cex=0.7)
mtext(text=bquote(paste("k=10","         ","k=7", "         ","k=5")), side = 1, line = 0, cex=0.7)
mtext(side = 4, las=1, outer=FALSE, text=expression(phi==0.9), line = 1, cex=0.7)

par(fig = c(0, 1, 0, 1), oma = c(0, 0, 0, 0), mar = c(0, 0, 0, 0), new = TRUE)
plot(0, 0, type = "n", bty = "n", xaxt = "n", yaxt = "n")
legend("bottom", c("With Recycled Indls","Without Recycled Indls"), xpd = TRUE, horiz = TRUE, inset = c(0, 0), bty = "n", pch = c(15,15), col = c(colors[2],colors[3]), cex = 1)
```


> \textsc{Figure 3:} \textsl{Simulation results for data with super-population size $N=1000$ with 100\% double-tagging for different capture probabilities ($p=0.2,0.5,0.9$) and constant survival ($\phi=0.9$) and tag retention probabilities ($\lambda=0.2$) using the JSTL model from experiments with $k=10, 7,$ and $5$ sample-times. Boxplots of the estimates of $N$ for the model analyzed with and without the recycled individuals are provided.} 


There is more bias in $\hat{N}$ due to recycled individuals in longer experiments (Figure 3). With a larger number of sampling occasions, there is more time for individuals to be captured and tagged, lose their tags, and survive to be recaptured (be recycled). In shorter studies, there are fewer numbers of recycled individuals and thus the bias in $\hat{N}$ due to recycled individuals is lower although not unnoticable in the worst case scenarios (low tag retention, high survival and high capture probabilities). Boxplots of super-population size ($N$) for all scenarios are available in the Appendix (Figures A19-A24).

```{r Figure4_N_j,echo=FALSE, fig.height=3}
#Tag Retention Low
par(mfrow=c(2,3),oma=c(5,5,2,4),mai=c(0.1,0.1,0.1,0.1))
i=1
repeat{
plot(1:10, get(paste("BIASrecycled2.",i,sep=""))[14:23]-get(paste("BIAS2.",i,sep=""))[14:23],axes=F,type="o", las=2, pch=15,col=colors[3],xlab=NA, ylab=NA, ylim=c(-0.25,3.5))
lines(1:10, get(paste("BIASrecycled2.",i+1,sep=""))[14:23]-get(paste("BIAS2.",i+1,sep=""))[14:23], type="o", pch=17,col=colors[2])
lines(1:10, get(paste("BIASrecycled2.",i+2,sep=""))[14:23]-get(paste("BIAS2.",i+2,sep=""))[14:23], type="o", pch=19,col=colors[1])

box()

if(i==1){
axis(side=2, las=2, cex=0.7)  
mtext(side = 3, outer=FALSE, text=bquote(paste(" p = ",.(globalP[i]))), line = 1, cex=0.7)
}

if(i==4){
mtext(side = 3, outer=FALSE, text=bquote(paste(" p = ",.(globalP[i]))), line = 1, cex=0.7)
}

if(i==7){
mtext(side = 3, outer=FALSE, text=bquote(paste(" p = ",.(globalP[i]))), line = 1, cex=0.7)
mtext(side = 4, outer=FALSE, text=bquote(paste(phi," = ",.(globalPhi[i]))), line = 1, cex=0.7, las=1)
}

if(i==10){
axis(side=1)
axis(side=2, las=2, cex=0.7)
}

if(i==13){
axis(side=1)  
}

if(i==16){
axis(side=1)
mtext(side = 4, las=1, outer=FALSE, text=bquote(paste(phi," = ",.(globalPhi[i]))), line = 1, cex=0.7)
}

if(i==19){
axis(side=1)
axis(side=2, las=2, cex=0.7)
}

if(i==22){
axis(side=1)  
}

if(i==25){
axis(side=1)
mtext(side = 4, las=1, outer=FALSE, text=bquote(paste(phi," = ",.(globalPhi[i]))), line = 1, cex=0.7)
}

i=i+3
if(i>18){break}
}
mtext(side = 1, outer=TRUE, "Sampling Occasions", line = 2, cex=0.7)
mtext(side = 2, outer=TRUE, "Relative Bias in Abundance Estimates at Each", line = 3, cex=0.7)
mtext(side = 2, outer=TRUE, "Sampling Occasion Due to Recycled Individuals", line = 2, cex=0.7)

par(fig = c(0, 1, 0, 1), oma = c(0, 0, 0, 0), mar = c(0, 0, 0, 0), new = TRUE)
plot(0, 0, type = "n", bty = "n", xaxt = "n", yaxt = "n")
legend("bottom", c("0.9","0.5","0.2"), xpd = TRUE, horiz = TRUE, inset = c(0, 0), lty=1, bty = "n", pch = c(15,17,19), col =colors[3:1], cex = 1)
```

> \textsc{Figure 4:} \textsl{Simulation results for data with super-population size N=100 000 with 100\% double-tagging for different tag retention probabilities ($\lambda=0.2,0.5,0.9$), survival probabilities ($\phi=0.2,0.5,0.9$), and different capture probabilities ($p=0.2,0.5,0.9$) using the JSTL model from a ten-sample-time study. The difference in mean relative bias of the abundance estimates at each time period ($\hat{N_j}$) between the model analyzed with and without the recycled individuals is provided. Note that lines are added between the points to emphasize the difference in values; no models were fit to generate these lines.}



In general, the bias due to recycled individuals in the $\hat{N}_j$'s follow a similar pattern to the bias due to recycled individuals in $\hat{N}$, with relative bias in the $\hat{N}_j$'s increasing as tag retention decreases, survival increases and capture probability increases (Figure 4). For all scenarios, the relative bias in the estimates of abundance at each sample time $j$ is smaller for earlier sampling occasions and larger for later sampling occasions. Since the estimates of the population sizes at each time $j$ are computed iteratively as $\hat{N}_{j+1}=\hat{\phi}(\hat{N_j})+\hat{b_j}(\hat{N})$, any bias in the earlier abundance estimates is magnified in the later sampling occasions abundance estimates. The scenario with $\phi=0.5$, $p=0.9$, and $\lambda=0.2$ appears to have very high relative bias in the abundance estimates in later sampling occasions (>3 for $\hat{N}_{10}$), which was caused by a combination of more upward bias in the survival estimates for the analysis with recycled recycled individuals than without (Figure A14) as well as upward bias in the super-population size estimates. Plots of the mean abundance estimates for all scenarios are available in the Appendix (Figures A17-A28). 




#Discussion
We fit the time-homogeneous JSTL model to simulated data from 108 different parameter combinations of super-population size (N=1000,100000), fraction double-tagged ($T_2=0.5,1$), survival probability ($\phi=0.2,0.5,0.9$), capture probability ($p=0.2,0.5,0.9$) and tag retention probability ($\lambda=0.2,0.5,0.9$) for ten sampling occasions. For the super-population size of 1000, we also examine experiments with five and seven sampling occasions.  While these models do not cover all possible realistic mark-recapture experiments, our simulations are sufficient to show that the JSTL abundance estimates can be substantially biased by recycled individuals, especially when tag-retention is low combined with high survival, high capture rates, or both. This effect is especially noticable in longer experiments. This contradicts the previous assumption that the effect of recycled individuals is negligible in mark-recapture models. However, we show that in general, recycled individuals have little effect on the accuracy of the survival, capture, and tag-retention probability estimates.  

Although our study provides some evidence that recycled individuals have an effect on estimators of the JSTL model in particular situations, there is room for improvement in our approach and questions remain for future work. Our analysis only examined three levels of survival, capture, and tag-retention probabilities (Low=0.2, Medium=0.5 and High=0.9). Future work could examine more closely the effect of recycled individuals on abundance estimates by examining more levels of survival, capture, and tag-retention probabilities. Additionally, future work could examine the effect of recycled individuals in situations where survival, capture or tag-retention probabilities are thought to be time-varying. 

For researchers interested in conducting and analyzing mark-recapture studies, we stress the importance of using tags with high retention rates, especially in situations where survival and capture rates are suspected to be high. As long as tag-retention is high, the JSTL estimator of population size is not affected by recycled individuals. In situations where it is possible to recognize if an individual has been captured previously (by scarring, marking, etc), excluding these recycled individuals from the analysis can improve accuracy of the abundance estimates. Permanent marking should be used where possible. If researchers are only interested in the survival rates, they do not need to be concerned with the effect of recycled individuals regardless of the study's tag-retention rates. 

#Acknowledgements
Simulation studies and analyses were run on WestGrid/Compute Canada with assistance from Dr. Belaid Moa. 

#References
Arnason, A.N. and Mills, K.H. (1981), Bias and loss of precision due to tag loss in Jolly-Seber estimates for mark-recapture experiments, \textit{Canadian Journal of Fisheries and Aquatic Science 38}, 1077-1095.

Cowen, L. and Schwarz, C.J. (2006), The Jolly-Seber model with tag loss, \textit{Biometrics 62}, 699-705.

Jolly, G. (1965), Explicit estimates from capture-recapture data with both death and immigration-stochastic model, \textit{Biometrika 52}, 225-247. 

Pollock, K.H., Nichols, J.D., Brownie, C., and Hines, J.E. (1990), Statistical inference for capture-recapture experiments, \textit{Wildlife Monographs 107}, 3-97.

R Core Team (2014). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL http://www.R-project.org/.

Schwarz, C.J. and Arnason, A.N. (1996), A general methodology for the analysis of capture-recapture experiments in open populations, \textit{Biometrics 52}, 860-873.

Seber, G. (1965), A note on the multiple recapture census, \textit{Biometrika 52}, 249-259.

Seber, G. and Felton, R. (1981), Tag loss and the Peterson mark-recapture experiment, \textit{Biometrika 68}, 211-219.

Xu, Y., Cowen, L.L.E. and Gardner, C. (2014), Group heterogeneity in the Jolly-Seber-tag-loss model, \textit{Statistical Methodology 17}, 3-16.

 



